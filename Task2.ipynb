{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opendatasets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59125c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'https://www.kaggle.com/datasets/sachinkumar413/diabetic-retinopathy-dataset'\n",
    "od.download(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcbb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '.\\diabetic-retinopathy-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = os.listdir('.\\diabetic-retinopathy-dataset')\n",
    "Healthy = os.listdir('.\\diabetic-retinopathy-dataset/Healthy')\n",
    "Mild = os.listdir('.\\diabetic-retinopathy-dataset/Mild DR')\n",
    "Moderate = os.listdir('.\\diabetic-retinopathy-dataset/Moderate DR')\n",
    "Proliferate = os.listdir('.\\diabetic-retinopathy-dataset/Proliferate DR')\n",
    "Severe = os.listdir('.\\diabetic-retinopathy-dataset/Severe DR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf94a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClasses:\", (data))\n",
    "print(\"\\nNumber of classes:\", len(data))\n",
    "print(\"\\nNumber of Healty images:\", len(Healthy))\n",
    "print(\"\\nNumber of Mild images:\", len(Mild))\n",
    "print(\"\\nNumber of Moderate images:\", len(Moderate))\n",
    "print(\"\\nNumber of Proliferate images:\", len(Proliferate),  \"\\n______________________________\\n\")\n",
    "print(\"\\nNumber of Severe images:\", len(Severe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset path\n",
    "Path_data = '.\\diabetic-retinopathy-dataset'\n",
    "\n",
    "# Create two lists to store paths of images and their labels\n",
    "img_paths = []\n",
    "labels =[]\n",
    "\n",
    "# Convert directory to list\n",
    "data = os.listdir(Path_data)\n",
    "\n",
    "# Get paths and Labels of classes and images in data\n",
    "for i in data:\n",
    "  class_path = os.path.join(Path_data, i)\n",
    "  img_list = os.listdir(class_path)\n",
    "\n",
    "  for img in img_list:\n",
    "    img_path = os.path.join(class_path, img)\n",
    "\n",
    "    img_paths.append(img_path)\n",
    "    labels.append(i)\n",
    "    \n",
    "# Convert two lists of imgpaths and their labels into series\n",
    "Paths = pd.Series(img_paths, name = 'Paths')\n",
    "Labels = pd.Series(labels, name = 'Labels')\n",
    "\n",
    "# Concatenate them in one Dataframe called df\n",
    "df= pd.concat([Paths, Labels], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e877d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "from tensorflow .keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, valid  and test dataframes\n",
    "train, testval = train_test_split(df, test_size = 0.2, shuffle = True, random_state = 123)\n",
    "valid, test = train_test_split(testval, test_size = 0.5, shuffle = True, random_state = 123)\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Valid shape:\", valid.shape)\n",
    "print(\"Test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6934d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "img_size = (224, 224) # Standard value (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "\n",
    "#Create generators\n",
    "tr_G = ImageDataGenerator(\n",
    "  zca_whitening=True,\n",
    "  rotation_range=30.,\n",
    "  fill_mode='nearest')\n",
    "\n",
    "V_G = ImageDataGenerator()\n",
    "t_G = ImageDataGenerator()\n",
    "\n",
    "#Generate Appropriate Data for fitting into model\n",
    "Train = tr_G.flow_from_dataframe(train, x_col = 'Paths', y_col = 'Labels', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = True, batch_size = batch_size)\n",
    "Valid = V_G.flow_from_dataframe(valid, x_col = 'Paths', y_col = 'Labels', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = True, batch_size = batch_size)\n",
    "Test = t_G.flow_from_dataframe(test, x_col = 'Paths', y_col = 'Labels', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = False, batch_size = batch_size)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f0e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_index = Train.class_indices\n",
    "print(L_index)\n",
    "Keys = list(L_index.keys())\n",
    "print(Keys)\n",
    "imgs, labels = next(Train)\n",
    "plt.figure(figsize= (15, 15))\n",
    "for i in range(8):\n",
    "  plt.subplot(3, 4, i +1)\n",
    "  im = imgs[i]/255\n",
    "  plt.imshow(im)\n",
    "\n",
    "  #Labelling\n",
    "  index = np.argmax(labels[i])\n",
    "  label = Keys[index]\n",
    "  plt.title(label, color = 'purple')\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Preparation\n",
    "n_classes = len(list(Train.class_indices.keys()))\n",
    "print(n_classes)\n",
    "\n",
    "img_shape=(img_size[0], img_size[1], 3)\n",
    "model_name='EfficientNetB3'\n",
    "base_model= EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n",
    "\n",
    "base_model.trainable=True\n",
    "x=base_model.output\n",
    "x=BatchNormalization(axis=-1, momentum=0.999, epsilon=0.001 )(x)\n",
    "\n",
    "x = Dense(1024, kernel_regularizer = regularizers.l2(l = 0.01),activity_regularizer=regularizers.l1(0.005),\n",
    "          bias_regularizer=regularizers.l1(0.005) ,activation='relu')(x)\n",
    "\n",
    "x=Dropout(rate=.2, seed=123)(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer = regularizers.l2(l = 0.01),activity_regularizer=regularizers.l1(0.005),\n",
    "          bias_regularizer=regularizers.l1(0.005) ,activation='relu')(x)\n",
    "\n",
    "x=Dropout(rate=.3, seed=123)(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.01),activity_regularizer=regularizers.l1(0.005),\n",
    "          bias_regularizer=regularizers.l1(0.005) ,activation='relu')(x)\n",
    "\n",
    "x=Dropout(rate=.4, seed=123)(x)\n",
    "\n",
    "output=Dense(n_classes, activation='softmax')(x)\n",
    "model=Model(inputs=base_model.input, outputs=output)\n",
    "lr=.0001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='elu'))\n",
    "model.add(Dense(256, activation='elu'))\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb73c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  Adamax(learning_rate=0.0001),\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabf599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "history = model.fit(x= Train, epochs= epochs, verbose= 1, validation_data= Valid,validation_steps= None, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy and loss of Train\n",
    "tr_acc = history.history['acc']\n",
    "tr_loss = history.history['loss']\n",
    "\n",
    "# accuracy and loss or Valid\\\n",
    "v_acc = history.history['val_acc']\n",
    "v_loss = history.history['val_loss']\n",
    "\n",
    "# Highest value of v_acc by getting its index\n",
    "index_acc = np.argmax(v_acc)\n",
    "high_Vacc = v_acc[index_acc]\n",
    "\n",
    "# Lowest value of v_loss by getting index\n",
    "index_loss = np.argmin(v_loss)\n",
    "low_Vloss = v_loss[index_loss]\n",
    "\n",
    "# Number of epochs based on length of tr_acc values\n",
    "Epochs =[]\n",
    "for i in range(len(tr_acc)):\n",
    "  Epochs.append (i+1)\n",
    "\n",
    "# Define best epoch\n",
    "best_acc = f'Best epoch accuracy = {str(index_acc +1)}'\n",
    "best_loss = f'Best epoch loss = {str(index_loss+1)}'\n",
    "\n",
    "print(best_acc)\n",
    "print(best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe992b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Subplot 1 for best epoch accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(Epochs, tr_acc, \"g\", label = \"Train Accuarcy\")\n",
    "plt.plot(Epochs, v_acc, \"r\", label = \"Valid Accuarcy\")\n",
    "plt.scatter(index_acc+1, high_Vacc, s = 150, color = 'purple', label = best_acc)\n",
    "plt.title(\"Accuracy: Train vs Valid\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot2 for best epoch loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(Epochs, tr_loss, \"g\", label = \"Train Loss\")\n",
    "plt.plot(Epochs, v_loss, \"r\", label = \"Valid Loss\")\n",
    "plt.scatter(index_loss+1, low_Vloss, s = 150, color = 'purple', label = best_loss)\n",
    "plt.title(\"Loss: Train vs Valid\")\n",
    "plt. xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e04895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_scores = model.evaluate(Train, verbose = 1)\n",
    "Valid_scores = model.evaluate(Valid, verbose = 1)\n",
    "Test_scores = model.evaluate(Test, verbose = 1)\n",
    "print('\\nTrain Scores: \\n    accuracy:', Train_scores[1], '\\n      Loss:', Train_scores[0], '\\n________________________')\n",
    "print('Valid Scores: \\n    accuracy:', Valid_scores[1], '\\n      Loss:', Valid_scores[0], '\\n________________________')\n",
    "print('Test Scores: \\n    accuracy:', Test_scores[1], '\\n      Loss:', Test_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(Test)\n",
    "y_pred = np.argmax(predictions, axis = 1)\n",
    "\n",
    "# Checking predictions\n",
    "print(predictions)\n",
    "print()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93698122",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_cl_ind = Test.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec92a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(Test_cl_ind.keys())\n",
    "confusion_matrix(Test.classes, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(Test.classes, y_pred, target_names = classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
